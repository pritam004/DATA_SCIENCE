{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pds3olsnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQBvOdOXLouh",
        "colab_type": "code",
        "outputId": "82b33a8f-3fa3-41bd-fbf1-f954bf1c7a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        " from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive' ,force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODsnl8-SCOLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_U4PHQUMF0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "data=pd.read_csv(\"/content/gdrive/My Drive/datasets/pdsass3/years.train\",header=None)\n",
        "data=data.to_numpy()\n",
        "labels=data[:,0]\n",
        "data=data[:,1:]\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "data=normalize(data)\n",
        "\n",
        "label_max=max(labels)\n",
        "label_min=min(labels)\n",
        "labels=(labels-label_min)/(label_max-label_min)\n",
        "def find_final(y):\n",
        "  return (y*(label_max-label_min) +label_min)\n",
        "train_data=data[:300000]\n",
        "train_label=labels[:300000]\n",
        "train_label=(train_label-label_min)/(label_max-label_min)\n",
        "test_data=data[300000:]\n",
        "test_label=labels[300000:]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZHqWfwYNe5B",
        "colab_type": "code",
        "outputId": "78c54cf2-4253-41f4-f57b-234440fc63f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train_data.shape[1], activation='relu'))\n",
        "NN_model.add(Dropout(.3))\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               11648     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 176,513\n",
            "Trainable params: 176,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjAwfX6YNh3i",
        "colab_type": "code",
        "outputId": "1b573afe-5b95-4123-d682-29d80d14ae7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = NN_model.fit(train_data, train_label, epochs=100, batch_size=2048, validation_split = 0.1)\n",
        "\n",
        "ypred = NN_model.predict(test_data)\n",
        "ypred=find_final(ypred)\n",
        "print(np.sqrt(mse(ypred,test_label)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 270000 samples, validate on 30000 samples\n",
            "Epoch 1/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 2/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 3/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 4/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 5/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 6/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 7/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 8/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 9/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 10/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 11/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 12/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 13/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 14/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 15/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 16/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 17/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 18/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 19/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 20/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 21/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 22/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 23/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 24/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 25/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 26/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 27/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 28/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 29/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 30/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 31/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 32/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 33/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 34/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 35/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 36/100\n",
            "270000/270000 [==============================] - 8s 28us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 37/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 38/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 39/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 40/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 41/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 42/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 43/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 44/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 45/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 46/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 47/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 48/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 49/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 50/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 51/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 52/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 53/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 54/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 55/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 56/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 57/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 58/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 59/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 60/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 61/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 62/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 63/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 64/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 65/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 66/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 67/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 68/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 69/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 70/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 71/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 72/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 73/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 74/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 75/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 76/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 77/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 78/100\n",
            "270000/270000 [==============================] - 7s 28us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 79/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 80/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 81/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 82/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 83/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 84/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 85/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 86/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 87/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 88/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 89/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 90/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 91/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 92/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 93/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 94/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 95/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 96/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 97/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 98/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 99/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 100/100\n",
            "270000/270000 [==============================] - 7s 27us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "1997.8652796099482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etsu6mW81pjp",
        "colab_type": "code",
        "outputId": "9d8508d1-4e28-402a-d3a1-44ad258fd96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ypred = NN_model.predict(test_data)\n",
        "\n",
        "\n",
        "ypred=find_final(ypred)\n",
        "test_label=find_final(test_label)\n",
        "print(np.sqrt(mse(ypred,test_label)))\n",
        "\n",
        "\n",
        "for i in range(100):\n",
        "  print (str(ypred[i])+\"  \"+ str(test_label[i]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.36903296721091\n",
            "[2003.9923]  2005.0\n",
            "[2002.5846]  2005.0\n",
            "[2006.9012]  2005.0\n",
            "[2004.4752]  2005.0\n",
            "[2003.0012]  2005.0\n",
            "[2003.6938]  2005.0\n",
            "[2002.1555]  2005.0\n",
            "[2002.533]  2006.0\n",
            "[2001.1855]  2005.0\n",
            "[2000.8519]  2005.0\n",
            "[2002.5251]  2009.0\n",
            "[2004.9998]  2009.0\n",
            "[2005.1051]  2009.0\n",
            "[2004.8591]  2009.0\n",
            "[2002.1737]  2009.0\n",
            "[2003.5209]  2009.0\n",
            "[2002.3937]  2009.0\n",
            "[2004.0376]  2009.0\n",
            "[2004.6858]  2009.0\n",
            "[2000.5322]  2003.0\n",
            "[2003.6237]  2003.0\n",
            "[2003.7063]  2003.0\n",
            "[2001.954]  2003.0\n",
            "[1999.8616]  2003.0\n",
            "[2002.4905]  2003.0\n",
            "[2001.6538]  2003.0\n",
            "[2001.3738]  2003.0\n",
            "[2000.0597]  2003.0\n",
            "[2003.3098]  2003.0\n",
            "[1999.7637]  2003.0\n",
            "[1999.0819]  2003.0\n",
            "[1995.0436]  2003.0\n",
            "[2002.1385]  2003.0\n",
            "[1997.4849]  2005.0\n",
            "[1990.8765]  2005.0\n",
            "[2002.1421]  2005.0\n",
            "[2001.4946]  2005.0\n",
            "[2002.6443]  2005.0\n",
            "[1994.9967]  2005.0\n",
            "[2002.2203]  2005.0\n",
            "[1998.3219]  2005.0\n",
            "[1991.9507]  2005.0\n",
            "[2001.0894]  2005.0\n",
            "[2003.5029]  2005.0\n",
            "[2001.4877]  2005.0\n",
            "[2001.7427]  2005.0\n",
            "[1986.2493]  1996.0\n",
            "[1986.1929]  1988.0\n",
            "[2000.3876]  2005.0\n",
            "[1998.5964]  2007.0\n",
            "[1998.7167]  2006.0\n",
            "[1994.3638]  2006.0\n",
            "[1983.3225]  2006.0\n",
            "[1999.828]  2006.0\n",
            "[2002.6273]  2006.0\n",
            "[1994.1855]  2006.0\n",
            "[1990.6512]  2006.0\n",
            "[2003.5526]  2009.0\n",
            "[1989.9517]  1990.0\n",
            "[1996.8505]  1993.0\n",
            "[1990.4961]  1992.0\n",
            "[1998.8005]  2006.0\n",
            "[2004.9803]  2006.0\n",
            "[2001.6716]  2006.0\n",
            "[2003.4004]  2006.0\n",
            "[2004.12]  2006.0\n",
            "[2004.4755]  2006.0\n",
            "[2002.886]  2006.0\n",
            "[2004.7255]  2006.0\n",
            "[2004.2307]  2006.0\n",
            "[2003.1622]  2006.0\n",
            "[2005.5076]  2006.0\n",
            "[2004.1077]  2006.0\n",
            "[2002.6348]  2006.0\n",
            "[2001.2628]  2010.0\n",
            "[2003.7092]  2009.0\n",
            "[2002.2627]  2009.0\n",
            "[2003.099]  2009.0\n",
            "[2002.7806]  2009.0\n",
            "[2001.4851]  2009.0\n",
            "[2001.702]  2009.0\n",
            "[1999.2646]  2009.0\n",
            "[2003.2733]  2009.0\n",
            "[2003.7976]  2009.0\n",
            "[2003.0642]  2009.0\n",
            "[2002.8755]  2009.0\n",
            "[2003.7135]  2005.0\n",
            "[2003.4067]  1999.0\n",
            "[2002.0891]  1999.0\n",
            "[2003.4197]  1999.0\n",
            "[2002.8333]  1999.0\n",
            "[2001.1763]  1999.0\n",
            "[2003.7422]  1998.0\n",
            "[2004.1213]  1999.0\n",
            "[2002.881]  1999.0\n",
            "[2002.2424]  1999.0\n",
            "[1991.2684]  1999.0\n",
            "[2002.4329]  1999.0\n",
            "[2002.569]  1999.0\n",
            "[2002.8053]  1999.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}