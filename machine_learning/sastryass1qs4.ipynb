{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sastryass1qs4.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1K5VPEzynHa",
        "colab_type": "code",
        "outputId": "4ce02e32-dd1f-4b67-8a79-10c49f77e2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive' ,force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTeGAy27yp-w",
        "colab_type": "text"
      },
      "source": [
        "**sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHu6uCDey-Kl",
        "colab_type": "text"
      },
      "source": [
        "The final problem is about classifying documents. The data set con-\n",
        "sists of 2000 moview reviews and it is a 2-class problem. (The data is\n",
        "in the file sentiment analysis.csv). For this data you explore a naive\n",
        "Bayes classifier using two different feature vectors: (i). ‘bag-of-word’\n",
        "representation where each feature is binary, (ii). TF-IDF based feature\n",
        "vector. Discuss the performance of the classifiers. In this problem the\n",
        "full data is given as one file to you. part of your job is to decide how\n",
        "to use the data to learn the classifier and then test the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQDjb_VryuD3",
        "colab_type": "code",
        "outputId": "75111382-ae39-4597-ddfd-26e05d93f2f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np, math,re,random\n",
        "import scipy.spatial\n",
        "# first neural network with keras tutorial\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "...\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "#from pomegranate import *\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import future\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from bs4 import BeautifulSoup  \n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.classify import NaiveBayesClassifier\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKAHDbyYzeCn",
        "colab_type": "text"
      },
      "source": [
        "function to evaluate the performance of classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n78MfRdjzLW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelEvaluation(predictions, y_test_set):\n",
        "    #Print model evaluation to predicted result \n",
        "    \n",
        "    print (\"\\nAccuracy on validation set: {:.4f}\".format(accuracy_score(y_test_set, predictions)))\n",
        "    #print \"\\nAUC score : {:.4f}\".format(roc_auc_score(y_test_set, predictions))\n",
        "    print (\"\\nClassification report : \\n\", metrics.classification_report(y_test_set, predictions))\n",
        "    print (\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test_set, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEc1CYup1zwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjLk9C7KzP7H",
        "colab_type": "code",
        "outputId": "d1e8e88d-db25-45ce-b871-f09135db3391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "sentiment_analysis = pd.read_csv(\"/content/gdrive/My Drive/datasets/prnnass1/sentiment_analysis.csv\")\n",
        "#print(sentiment_analysis['text'][1])\n",
        "#df = pd.DataFrame(np.random.randn(2000, 2))\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "#vectorizer1= TfidfTransformer(5)\n",
        "X = vectorizer.fit_transform(sentiment_analysis['text'])\n",
        "tfidf = TfidfVectorizer(min_df=2) #minimum document frequency of 5\n",
        "A = tfidf.fit_transform(sentiment_analysis['text'])\n",
        "#print(vectorizer.get_feature_names())\n",
        "\n",
        "#A=vectorizer1.fit_transform(sentiment_analysis['text'])\n",
        "#A\n",
        "#X_test=vectorizer.fit_transform(sentiment_analysis['text'][1500:])\n",
        "#X\n",
        "#vectorizer.get_feature_names()\n",
        "X=X.toarray()\n",
        "A=A.toarray()\n",
        "#print(X)\n",
        "\n",
        "# X_test=X[1500:2000,:]\n",
        "# X=X[:1500,:]\n",
        "# print(X.shape,X_test.shape)\n",
        "# #X\n",
        "Y=vectorizer.fit_transform(sentiment_analysis['class'])\n",
        "B=tfidf.fit_transform(sentiment_analysis['class'])\n",
        "Y=Y.toarray()\n",
        "Y\n",
        "y=[]\n",
        "b=[]\n",
        "for i in Y:\n",
        "    if i[0]==0 and i[1]==1:\n",
        "        y.append(1)\n",
        "        b.append(1)\n",
        "    else :\n",
        "        y.append(-1)\n",
        "        b.append(-1)\n",
        "rund=np.random.randint(0,2000,500)\n",
        "X_train=[]\n",
        "X_test=[]\n",
        "y_train=[]\n",
        "y_test=[]\n",
        "A_train=[]\n",
        "A_test=[]\n",
        "b_train=[]\n",
        "b_test=[]\n",
        "for i in range (2000):\n",
        "    if i in rund :\n",
        "        X_test.append(X[i])\n",
        "        y_test.append(y[i])\n",
        "        A_test.append(A[i])\n",
        "        b_test.append(b[i])\n",
        "    else:\n",
        "        X_train.append(X[i])\n",
        "        y_train.append(y[i])\n",
        "        A_train.append(A[i])\n",
        "        b_train.append(b[i])\n",
        "        \n",
        "#y=np.array(y)\n",
        "#print(y[-500:])\n",
        "#y_test=y[-500:]\n",
        "#y=y[:1500]\n",
        "#print(y_test.shape)\n",
        "gnb = GaussianNB()\n",
        "mnb=MultinomialNB()\n",
        "\n",
        "gnb.fit(X_train,y_train)\n",
        "gnb.score(X_test,y_test)\n",
        "predictions = gnb.predict(X_test)\n",
        "modelEvaluation(predictions, y_test)\n",
        "\n",
        "print(\"\\n\\nnow tfidf\\n\\n\")\n",
        "\n",
        "gnb.fit(A_train,b_train)\n",
        "gnb.score(A_test,b_test)\n",
        "predictions = gnb.predict(A_test)\n",
        "modelEvaluation(predictions, b_test)\n",
        "\n",
        "\n",
        "# sentiment_classifier = NaiveBayesClassifier.train(X[:1500])\n",
        "# prediction=nltk.classify(sentiment_classifier, A_test)\n",
        "# modelEvaluation(predictions, b_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on validation set: 0.6463\n",
            "\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.61      0.62       212\n",
            "           1       0.65      0.68      0.67       229\n",
            "\n",
            "    accuracy                           0.65       441\n",
            "   macro avg       0.65      0.65      0.65       441\n",
            "weighted avg       0.65      0.65      0.65       441\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            " [[130  82]\n",
            " [ 74 155]]\n",
            "\n",
            "\n",
            "now tfidf\n",
            "\n",
            "\n",
            "\n",
            "Accuracy on validation set: 0.6372\n",
            "\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.58      0.60       212\n",
            "           1       0.64      0.69      0.67       229\n",
            "\n",
            "    accuracy                           0.64       441\n",
            "   macro avg       0.64      0.63      0.63       441\n",
            "weighted avg       0.64      0.64      0.64       441\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            " [[122  90]\n",
            " [ 70 159]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7736a9198fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0msentiment_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mmodelEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShdYYlm011gV",
        "colab_type": "code",
        "outputId": "10de2213-c3f4-434e-c343-67d84030cd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(39363, input_dim=39363, activation='relu'))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "...\n",
        "# first neural network with keras tutorial\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "...\n",
        "...\n",
        "...\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "...\n",
        "X_train=np.array(X_train)\n",
        "y_train=np.array(y_train)\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=10)\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}